# DataStream Operations

## Core DataStream Methods

### Construction
```go
// Create new DataStream
ds := datastreams.New[T](ctx, inputChan, errChan)

// Attach WaitGroup for goroutine management
ds = ds.WithWaitGroup(&sync.WaitGroup{})
```

### Basic Transformations
```go
// Process items
ds = ds.Run(func(v T) (T, error) {
    // Transform v
    return transformed, nil
}, Params{BufferSize: 1000})

// Filter items
ds = ds.Filter(func(v T) (bool, error) {
    return shouldKeep, nil
}, Params{SkipError: true})

// Transform types
ds = ds.Map(func(v T) (U, error) {
    return convert(v), nil
})
```

### Concurrency Operations
```go
// Fan out to multiple workers
ds = ds.FanOut(Params{Num: runtime.NumCPU()})

// Fan in multiple streams
ds = ds.FanIn()

// Broadcast to multiple consumers
ds = ds.Broadcast(Params{Num: 3})

// Split into two streams
stream1, stream2 := ds.Tee()
```

## Advanced Operations

### Keyed Operations
```go
// Partition by key
keyed := ds.KeyBy[K](func(v T) K {
    return extractKey(v)
}, Params{BufferSize: 50})

// Apply windowing
windowed := keyed.Window(windowFunc, partitionFactory, Params{})
```

### Expansion and Collection
```go
// Expand items into multiple
ds = ds.Expand(func(v T) ([]U, error) {
    return expand(v), nil
})

// Take only N items
ds = ds.Take(Params{Num: 1000})

// Terminate if upstream is done
ds = ds.OrDone()
```

## Error Handling Patterns

### Skip Errors
```go
ds = ds.Run(processFunc, Params{
    SkipError: true,
    SegmentName: "processing-stage",
})
```

### Error Recovery
```go
ds = ds.Run(func(v T) (T, error) {
    result, err := process(v)
    if err != nil {
        // Log error and return fallback
        log.Printf("Error processing %v: %w", v, err)
        return fallbackValue, nil
    }
    return result, nil
})
```

## Performance Optimization

### Buffer Sizing
```go
// Use appropriate buffer sizes
ds = ds.Run(processFunc, Params{
    BufferSize: 1000, // Larger buffers reduce blocking
})
```

### Worker Scaling
```go
// Scale with available cores
ds = ds.FanOut(Params{
    Num: runtime.NumCPU(),
})
```

## Common Patterns

### Pipeline Stage
```go
func createStage[T any](ds DataStream[T]) DataStream[T] {
    return ds.
        Filter(filterFunc).
        Run(processFunc).
        Map(transformFunc)
}
```

### Conditional Processing
```go
ds = ds.Run(func(v T) (T, error) {
    if shouldProcess(v) {
        return process(v)
    }
    return v, nil // Pass through unchanged
})
```

### Batch Processing
```go
ds = ds.Window(
    batchWindowFunc,
    batchPartitionFactory,
    Params{BufferSize: 1000},
)
```
description:
globs:
alwaysApply: true
---
