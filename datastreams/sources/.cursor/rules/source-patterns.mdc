# Source Implementation Patterns

## Core Source Interface

### Sourcer Contract
```go
type Sourcer[T any] interface {
    Source(ctx context.Context, errStream chan<- error) datastreams.DataStream[T]
}
```

### Basic Source Implementation
```go
type BasicSource[T any] struct {
    data []T
}

func (s *BasicSource[T]) Source(ctx context.Context, errStream chan<- error) datastreams.DataStream[T] {
    outChan := make(chan T, len(s.data))
    
    go func() {
        defer close(outChan)
        for _, item := range s.data {
            select {
            case <-ctx.Done():
                return
            case outChan <- item:
            }
        }
    }()
    
    return datastreams.New(ctx, outChan, errStream)
}
```

## Built-in Source Types

### FromArray Source
```go
// Convert slice to source
data := []int{1, 2, 3, 4, 5}
source := sources.FromArray(data)

// Use with pipeline
pipeline := pipelines.New[int, int](ctx, source, errChan)
```

### FromChannel Source
```go
// Convert existing channel to source
inputChan := make(chan Data, 1000)
source := sources.FromChannel(inputChan)

// Use with pipeline
pipeline := pipelines.New[Data, Result](ctx, source, errChan)
```

### FromDataStream Source
```go
// Convert DataStream to source
ds := datastreams.New(ctx, inputChan, errChan)
source := sources.FromDataStream(ds)
```

## Custom Source Implementations

### Database Source
```go
type DatabaseSource[T any] struct {
    db        *sql.DB
    query     string
    args      []interface{}
    batchSize int
}

func (s *DatabaseSource[T]) Source(ctx context.Context, errStream chan<- error) datastreams.DataStream[T] {
    outChan := make(chan T, s.batchSize)
    
    go func() {
        defer close(outChan)
        
        rows, err := s.db.QueryContext(ctx, s.query, s.args...)
        if err != nil {
            errStream <- fmt.Errorf("failed to query database: %w", err)
            return
        }
        defer rows.Close()
        
        for rows.Next() {
            var item T
            if err := rows.Scan(&item); err != nil {
                errStream <- fmt.Errorf("failed to scan row: %w", err)
                continue
            }
            
            select {
            case <-ctx.Done():
                return
            case outChan <- item:
            }
        }
        
        if err := rows.Err(); err != nil {
            errStream <- fmt.Errorf("error iterating rows: %w", err)
        }
    }()
    
    return datastreams.New(ctx, outChan, errStream)
}
```

### File Source
```go
type FileSource[T any] struct {
    filePath string
    decoder  func([]byte) (T, error)
    batchSize int
}

func (s *FileSource[T]) Source(ctx context.Context, errStream chan<- error) datastreams.DataStream[T] {
    outChan := make(chan T, s.batchSize)
    
    go func() {
        defer close(outChan)
        
        file, err := os.Open(s.filePath)
        if err != nil {
            errStream <- fmt.Errorf("failed to open file: %w", err)
            return
        }
        defer file.Close()
        
        scanner := bufio.NewScanner(file)
        for scanner.Scan() {
            line := scanner.Bytes()
            
            item, err := s.decoder(line)
            if err != nil {
                errStream <- fmt.Errorf("failed to decode line: %w", err)
                continue
            }
            
            select {
            case <-ctx.Done():
                return
            case outChan <- item:
            }
        }
        
        if err := scanner.Err(); err != nil {
            errStream <- fmt.Errorf("error reading file: %w", err)
        }
    }()
    
    return datastreams.New(ctx, outChan, errStream)
}
```

### HTTP Source
```go
type HTTPSource[T any] struct {
    client   *http.Client
    endpoint string
    decoder  func([]byte) (T, error)
    interval time.Duration
}

func (s *HTTPSource[T]) Source(ctx context.Context, errStream chan<- error) datastreams.DataStream[T] {
    outChan := make(chan T, 1000)
    
    go func() {
        defer close(outChan)
        
        ticker := time.NewTicker(s.interval)
        defer ticker.Stop()
        
        for {
            select {
            case <-ctx.Done():
                return
            case <-ticker.C:
                if err := s.fetchAndEmit(ctx, outChan, errStream); err != nil {
                    errStream <- err
                }
            }
        }
    }()
    
    return datastreams.New(ctx, outChan, errStream)
}

func (s *HTTPSource[T]) fetchAndEmit(ctx context.Context, outChan chan<- T, errStream chan<- error) error {
    req, err := http.NewRequestWithContext(ctx, "GET", s.endpoint, nil)
    if err != nil {
        return fmt.Errorf("failed to create request: %w", err)
    }
    
    resp, err := s.client.Do(req)
    if err != nil {
        return fmt.Errorf("failed to fetch data: %w", err)
    }
    defer resp.Body.Close()
    
    body, err := io.ReadAll(resp.Body)
    if err != nil {
        return fmt.Errorf("failed to read response: %w", err)
    }
    
    item, err := s.decoder(body)
    if err != nil {
        return fmt.Errorf("failed to decode response: %w", err)
    }
    
    select {
    case <-ctx.Done():
        return ctx.Err()
    case outChan <- item:
        return nil
    }
}
```

### Generator Source
```go
type GeneratorSource[T any] struct {
    generator func() T
    count     int
    interval  time.Duration
}

func (s *GeneratorSource[T]) Source(ctx context.Context, errStream chan<- error) datastreams.DataStream[T] {
    outChan := make(chan T, 1000)
    
    go func() {
        defer close(outChan)
        
        if s.interval > 0 {
            ticker := time.NewTicker(s.interval)
            defer ticker.Stop()
            
            for i := 0; i < s.count; i++ {
                select {
                case <-ctx.Done():
                    return
                case <-ticker.C:
                    item := s.generator()
                    select {
                    case <-ctx.Done():
                        return
                    case outChan <- item:
                    }
                }
            }
        } else {
            for i := 0; i < s.count; i++ {
                select {
                case <-ctx.Done():
                    return
                case outChan <- s.generator():
                }
            }
        }
    }()
    
    return datastreams.New(ctx, outChan, errStream)
}
```

## Streaming Source Patterns

### Infinite Stream Source
```go
type InfiniteStreamSource[T any] struct {
    generator func() T
    interval  time.Duration
}

func (s *InfiniteStreamSource[T]) Source(ctx context.Context, errStream chan<- error) datastreams.DataStream[T] {
    outChan := make(chan T, 1000)
    
    go func() {
        defer close(outChan)
        
        ticker := time.NewTicker(s.interval)
        defer ticker.Stop()
        
        for {
            select {
            case <-ctx.Done():
                return
            case <-ticker.C:
                item := s.generator()
                select {
                case <-ctx.Done():
                    return
                case outChan <- item:
                }
            }
        }
    }()
    
    return datastreams.New(ctx, outChan, errStream)
}
```

### Backpressure-Aware Source
```go
type BackpressureSource[T any] struct {
    generator func() T
    maxBuffer int
}

func (s *BackpressureSource[T]) Source(ctx context.Context, errStream chan<- error) datastreams.DataStream[T] {
    outChan := make(chan T, s.maxBuffer)
    
    go func() {
        defer close(outChan)
        
        for {
            select {
            case <-ctx.Done():
                return
            case outChan <- s.generator():
                // This will block if the channel is full, providing backpressure
            }
        }
    }()
    
    return datastreams.New(ctx, outChan, errStream)
}
```

## Error Handling Patterns

### Graceful Error Handling
```go
func (s *Source[T]) Source(ctx context.Context, errStream chan<- error) datastreams.DataStream[T] {
    outChan := make(chan T, 1000)
    
    go func() {
        defer close(outChan)
        
        for {
            select {
            case <-ctx.Done():
                return
            default:
                item, err := s.generateItem()
                if err != nil {
                    // Send error but continue processing
                    select {
                    case <-ctx.Done():
                        return
                    case errStream <- fmt.Errorf("failed to generate item: %w", err):
                    }
                    continue
                }
                
                select {
                case <-ctx.Done():
                    return
                case outChan <- item:
                }
            }
        }
    }()
    
    return datastreams.New(ctx, outChan, errStream)
}
```

### Retry Logic
```go
func (s *Source[T]) Source(ctx context.Context, errStream chan<- error) datastreams.DataStream[T] {
    outChan := make(chan T, 1000)
    
    go func() {
        defer close(outChan)
        
        for {
            select {
            case <-ctx.Done():
                return
            default:
                item, err := s.generateItemWithRetry(ctx)
                if err != nil {
                    errStream <- err
                    continue
                }
                
                select {
                case <-ctx.Done():
                    return
                case outChan <- item:
                }
            }
        }
    }()
    
    return datastreams.New(ctx, outChan, errStream)
}

func (s *Source[T]) generateItemWithRetry(ctx context.Context) (T, error) {
    maxRetries := 3
    backoff := time.Millisecond * 100
    
    for attempt := 0; attempt < maxRetries; attempt++ {
        item, err := s.generateItem()
        if err == nil {
            return item, nil
        }
        
        if attempt < maxRetries-1 {
            select {
            case <-ctx.Done():
                return zero[T](), ctx.Err()
            case <-time.After(backoff):
                backoff *= 2 // Exponential backoff
            }
        }
    }
    
    return zero[T](), fmt.Errorf("failed after %d attempts", maxRetries)
}
```

## Performance Optimization

### Batch Processing
```go
type BatchSource[T any] struct {
    generator func() []T
    batchSize int
}

func (s *BatchSource[T]) Source(ctx context.Context, errStream chan<- error) datastreams.DataStream[T] {
    outChan := make(chan T, s.batchSize)
    
    go func() {
        defer close(outChan)
        
        for {
            select {
            case <-ctx.Done():
                return
            default:
                batch := s.generator()
                
                for _, item := range batch {
                    select {
                    case <-ctx.Done():
                        return
                    case outChan <- item:
                    }
                }
            }
        }
    }()
    
    return datastreams.New(ctx, outChan, errStream)
}
```

### Connection Pooling
```go
type PooledSource[T any] struct {
    pool    *sync.Pool
    factory func() Sourcer[T]
}

func (s *PooledSource[T]) Source(ctx context.Context, errStream chan<- error) datastreams.DataStream[T] {
    source := s.pool.Get().(Sourcer[T])
    defer s.pool.Put(source)
    
    return source.Source(ctx, errStream)
}
```

## Testing Sources

### Test Source
```go
type TestSource[T any] struct {
    items []T
}

func (s *TestSource[T]) Source(ctx context.Context, errStream chan<- error) datastreams.DataStream[T] {
    outChan := make(chan T, len(s.items))
    
    go func() {
        defer close(outChan)
        for _, item := range s.items {
            select {
            case <-ctx.Done():
                return
            case outChan <- item:
            }
        }
    }()
    
    return datastreams.New(ctx, outChan, errStream)
}
```

### Mock Source
```go
type MockSource[T any] struct {
    mock.Mock
}

func (s *MockSource[T]) Source(ctx context.Context, errStream chan<- error) datastreams.DataStream[T] {
    args := s.Called(ctx, errStream)
    return args.Get(0).(datastreams.DataStream[T])
}
```

## Best Practices

1. **Context Handling**: Always respect context cancellation
2. **Error Propagation**: Send errors to the error stream
3. **Resource Cleanup**: Use `defer` for proper cleanup
4. **Buffer Sizing**: Choose appropriate channel buffer sizes
5. **Backpressure**: Implement backpressure handling for infinite streams
6. **Batching**: Use batch processing for better performance
7. **Testing**: Create testable source implementations
8. **Monitoring**: Log performance metrics and errors
description:
globs:
alwaysApply: true
---
